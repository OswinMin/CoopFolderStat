\documentclass[12pt, a4paper, oneside]{article}
\usepackage{amsmath, amsthm, amssymb, appendix, bm, graphicx, hyperref, mathrsfs, makecell}
\usepackage{bbm, stfloats, subfigure, pythonhighlight, CJK, algorithm, algorithmicx, algpseudocode}
\usepackage{geometry}
\geometry{a4paper,left=2.5cm,right=2.5cm,top=3cm,bottom=3cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand\headrulewidth{.5pt}
\renewcommand\footrulewidth{0pt}
\setlength{\headheight}{15pt}
\fancyhead[L]{\textit{\leftmark}}
\fancyhead[R]{\thepage}

\title{\textbf{Federated Conformal Prediction General}}
\author{Min, Xia}
\date{\today}
\linespread{1.6}
\definecolor{lightBlue}{rgb}{0.274,0.41,0.879}
\definecolor{darckGreen}{rgb}{0.1797,0.543,0.3398}
%{\color{lightBlue}Text Here}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\renewcommand{\abstractname}{\Large\textbf{Abstract}}
\floatname{algorithm}{Algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document}
\maketitle
\setcounter{page}{1}
\pagenumbering{arabic}
\section[Section title sans citation]{Conformal Prediction General\cite{angelopoulos2023conformal}}
    \begin{definition}[Exchangebility]\cite{shafer2008tutorial}
        For any r.v. $x_1,\cdots,x_k$, we say they are exchangeable if for any permutation $\sigma:[k]\rightarrow[k]$(bijection), $(x_1,\cdots,x_k)\overset{d.}{=}(x_{\sigma(1)},\cdots,x_{\sigma(k)})$.
    \end{definition}


    For conformal prediction two classes of targets are studied.
    \begin{definition}[Marginal Coverage]
        $(X,Y)\in\mathbb{R}^p\times\mathbb{R}\sim P_{XY}$ which is unknown. Given training set $Tr=\{(X_i,Y_i)\}_{i=1}^n$, and test on $(X_{n+1},Y_{n+1})$, both i.i.d.


        $C_\alpha$  satisfies distribution-free marginal coverage at level $1-\alpha$ if
        \begin{equation*}
            P(Y_{n+1}\in C_\alpha(X_{n+1}))\geq 1-\alpha,\ \forall P_{XY}
        \end{equation*}
        The probability is with respect to $\{(X_i,Y_i)\}_{i=1}^{n+1}$.
    \end{definition}


    \begin{definition}[Conditional Coverage]
        $(X,Y)\in\mathbb{R}^p\times\mathbb{R}\sim P_{XY}$ which is unknown. Given training set $Tr=\{(X_i,Y_i)\}_{i=1}^n$, and test on $(X_{n+1},Y_{n+1})$, both i.i.d.


        $C_\alpha$  satisfies distribution-free marginal coverage at level $1-\alpha$ if
        \begin{equation*}
            P(Y_{n+1}\in C_\alpha(X_{n+1})\Big|X_{n+1}=x)\geq 1-\alpha,\ \forall P_{XY}
        \end{equation*}
        The probability is with respect to $\{(X_i,Y_i)\}_{i=1}^n$ and $Y_{n+1}$.
    \end{definition}


\section[Section title sans citation]{Federated Conformal Prediction Article1}
    Efficient Conformal Prediction under Data Heterogeneity\cite{plassier2024efficient}


    Idea: The marginal coverage is measured over all training data and test points. However, if there is a high variability in the coverage probability as a function of the training data, the test coverage probability may be substantially below $1-\alpha$ for a particular training set.
    \begin{definition}[empirical miscoverage rate]
        $\alpha(Tr)=P(Y_{n+1}\notin C_\alpha(X_{n+1})\Big|Tr)$
    \end{definition}
\newpage
\bibliographystyle{plain}
\bibliography{ref}
\end{document}